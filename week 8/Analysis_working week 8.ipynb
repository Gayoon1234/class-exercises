{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Examples\n",
    "\n",
    "These examples use the Iris dataset which is commonly used in online tutorials (https://archive.ics.uci.edu/ml/datasets/Iris).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt     # Matplotlib for low-level plot details\n",
    "import numpy as np                  # NumPy for fast numeric operations\n",
    "import pandas as pd                 # Pandas for datasets\n",
    "import seaborn as sns               # Seaborn for easier plotting\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from the UCI ML repository\n",
    "# The UCI website is pretty specific:\n",
    "# 1. Each dataset is in a subfolder\n",
    "# 2. The data file name is {name}.data\n",
    "#Anna - would you prefer to download this and have it stored locally rather than relying on a remote site?\n",
    "base_uri=\"https://archive.ics.uci.edu/ml/machine-learning-databases\"\n",
    "file_path = f\"{base_uri}/iris/iris.data\"\n",
    "# file_path = f\"{base_uri}/00623/DATA.csv\"\n",
    "# There are no column headers in the data file so manually specify them here\n",
    "iris_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "iris_df = pd.read_csv(file_path, names=iris_columns, index_col=False)\n",
    "\n",
    "#Anna - is having students enter their own numbers worth the effort involved?\n",
    "#set seed: students to add their own Student numbers here\n",
    "seed = 123845\n",
    "\n",
    "# Display details about the dataset\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html\n",
    "print(iris_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the first 20 records in the dataset\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n",
    "print(iris_df.head(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### Notes\n",
    "1. When working with Pandas axis=0 means a row operation and axis=1 means a column operation.\n",
    "2. The a subset of columns can be selected by creating a list of names e.g. ['var1', 'var2'].\n",
    "\n",
    "### Creating variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Calculate petal area\n",
    "iris_df[\"petal_area\"] = iris_df[\"petal_length\"] * iris_df[\"petal_width\"]\n",
    "\n",
    "# Example 2: Calculate mean sepal dimensions\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
    "sepal_names = [\"sepal_length\", \"sepal_width\"]\n",
    "iris_df[\"sepal_mean\"] = iris_df[sepal_names].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Categorical data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris 'class' attribute is currently an 'object' but is really categorical\n",
    "iris_df[\"flower_type\"] = iris_df[\"class\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Dropping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "iris_df.drop(\"class\", axis=1, inplace=True)\n",
    "# This is equivalent to:\n",
    "# iris_df.drop(columns=[\"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Observations/ rows of data\n",
    "\n",
    "Say I want to make a sample selection/ filter the sample according to two conditions:\n",
    "I would like to only look at samples that:\n",
    "1.\tHave a petal_length value >2.5 AND that have a petal_width value >1.5\n",
    "2.\tHave a (petal_length value >2.5 AND that have a petal_width value >1.5) OR petal_length value <2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df_2=iris_df[(iris_df.petal_length > 2.5) & (iris_df.petal_width >1.5)].copy()\n",
    "print(iris_df_2.head(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df_3=iris_df[((iris_df.petal_length > 2.5) & (iris_df.petal_width >1.5)) | iris_df.petal_length <2.5].copy()\n",
    "print(iris_df_3.head(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "### Basic Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "print(iris_df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]].describe())\n",
    "# This produces the same output:\n",
    "# print(iris_df.drop(\"flower_type\", axis=1).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Inter-quartile Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: Calculate the quantile(s) required\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html\n",
    "# Note: Sepal width is not required but used to demonstrate multi-variable use\n",
    "sepal_length_q25, sepal_width_q25 = iris_df[[\"sepal_length\", \"sepal_width\"]].quantile(0.25, axis=0)\n",
    "print(f\"Sepal length 25th percentile: {sepal_length_q25}\")\n",
    "print(f\"Sepal width 25th percentile: {sepal_width_q25}\")\n",
    "# Note: Also need 75th percentile for length to calculate IQR\n",
    "sepal_length_q75 = iris_df[\"sepal_length\"].quantile(0.75)\n",
    "print(f\"Sepal length 75th percentile: {sepal_length_q75}\")\n",
    "\n",
    "# Second: Calculate the IQR = Q75 - Q25\n",
    "sepal_length_iqr = sepal_length_q75 - sepal_length_q25\n",
    "print(f\"Sepal length IQR: {sepal_length_iqr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Counts / Frequency / Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of each Iris flower type are there?\n",
    "print(iris_df[\"flower_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the probability distribution for each flower type?\n",
    "print(iris_df[\"flower_type\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross tabulation\n",
    "# Create indicators for sepal length and width above or below mean\n",
    "iris_df[\"sepal_length_big\"] = iris_df[\"sepal_length\"]>iris_df[\"sepal_length\"].mean()\n",
    "iris_df[\"sepal_width_big\"] = iris_df[\"sepal_width\"]>iris_df[\"sepal_width\"].mean()\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html\n",
    "pd.crosstab(iris_df[\"sepal_length_big\"], iris_df[\"sepal_width_big\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage cross tabulation defaults to percentage of all values\n",
    "pd.crosstab(iris_df[\"sepal_length_big\"], iris_df[\"sepal_width_big\"], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this by normalize parameter (see documentation)\n",
    "pd.crosstab(iris_df[\"sepal_length_big\"], iris_df[\"sepal_width_big\"], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean sepal dimension and petal area\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
    "iris_df[[\"sepal_mean\", \"petal_area\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Graphing\n",
    "\n",
    "The Seaborn Tutorial (https://seaborn.pydata.org/tutorial.html) is very useful.\n",
    "\n",
    "### Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic scatter plot\n",
    "# https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "# _ = ... is a loose convention meaning we don't care about the return value\n",
    "# Without this Jupyter Notebook will list an object reference before the graph\n",
    "_ = sns.scatterplot(data=iris_df, x=\"sepal_width\", y=\"sepal_length\")\\\n",
    "       .set(title=\"Sepal Width x Length\", xlabel=\"Width (cm)\", ylabel=\"Length (cm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also separate observations by flower types\n",
    "# In this case the name of the graph variable is used but the return\n",
    "# value of setting titles and axis labels is not important.\n",
    "g = sns.scatterplot(data=iris_df, x=\"sepal_width\", y=\"sepal_length\",\n",
    "                    hue=\"flower_type\", style=\"flower_type\", palette=\"deep\")\n",
    "_ = g.set(title=\"Sepal Width x Length\", xlabel=\"Width (cm)\", ylabel=\"Length (cm)\")\n",
    "_ = g.legend(title=\"Flower Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can plot linear regression lines automatically\n",
    "# https://seaborn.pydata.org/generated/seaborn.lmplot.html\n",
    "_ = sns.lmplot(data=iris_df, x=\"sepal_width\", y=\"sepal_length\", hue=\"flower_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petal area percentages of 2.5cm-squared bins\n",
    "# https://seaborn.pydata.org/generated/seaborn.histplot.html\n",
    "_ = sns.histplot(data=iris_df, x=\"petal_area\", binwidth=2.5, stat='percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.lineplot.html\n",
    "_ = sns.lineplot(data=iris_df, x=\"sepal_width\", y=\"sepal_length\", hue=\"flower_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Kernel Density Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One dimensional KDE\n",
    "# https://seaborn.pydata.org/generated/seaborn.kdeplot.html\n",
    "_ = sns.kdeplot(data=iris_df, x=\"petal_area\", palette=\"deep\", hue=\"flower_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two dimensional KDE\n",
    "_ = sns.kdeplot(data=iris_df, x=\"petal_width\", y=\"petal_length\", hue=\"flower_type\")\\\n",
    "       .set(title=\"Petal Length x Width Desnsity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Multiple plots together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-figures need to be configured manually\n",
    "# Uses the low-level features of matplotlib to create separate axes then plots onto them\n",
    "figure, axes = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "figure.suptitle(\"Distribution of Petal Width and Length\")\n",
    "_ = sns.kdeplot(data=iris_df, x=\"petal_width\", hue=\"flower_type\", palette=\"deep\", ax=axes[0])\n",
    "_ = sns.kdeplot(data=iris_df, x=\"petal_length\", hue=\"flower_type\", palette=\"deep\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint grids plot multiple forms of two variables\n",
    "# https://seaborn.pydata.org/generated/seaborn.jointplot.html\n",
    "g = sns.jointplot(data=iris_df, x=\"petal_width\", y=\"petal_length\", hue=\"flower_type\", palette=\"deep\")\n",
    "_ = g.plot_joint(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair grids put X by Y of all variables in a data frame\n",
    "# https://seaborn.pydata.org/generated/seaborn.PairGrid.html\n",
    "# You can achieve something similar with sns.pairplot but with less functionality\n",
    "g = sns.PairGrid(data=iris_df[[\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\", \"flower_type\"]], hue=\"flower_type\", palette=\"deep\")\n",
    "_ = g.map_diag(sns.histplot, multiple=\"dodge\")\n",
    "_ = g.map_lower(sns.kdeplot)\n",
    "_ = g.map_upper(sns.scatterplot, marker='.')\n",
    "_ = g.add_legend(title=\"Flower Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "_Note: Logistic regression is a classification task - predicting a flower type in this case. The regression in the name comes from the model using regression to estimate probabilities and then classify based on the highest probability._\n",
    "\n",
    "The Iris dataset plots above show the _setosa_ are linearly separable from _versicolor_ and _virginica_ but that these are not.\n",
    "\n",
    "This Logistic Regression example tried to separate _setosa_ from any other type (a binary classification task).\n",
    "\n",
    "Classification only uses $petal\\_width$ and $petal\\_length$ so the decision boundary can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recode the flower types into the binary classes\n",
    "# Y_TARGET = \"setosa\"\n",
    "# iris_df[Y_TARGET] = iris_df[\"flower_type\"].replace({\"Iris-setosa\": 1, \"Iris-versicolor\": 0, \"Iris-virginica\": 0})\n",
    "# print(iris_df[Y_TARGET].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "The graphs above suggest petal dimensions will return good results so subset to just those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training and Test Data\n",
    "# X_FEATURES = [\"petal_width\", \"petal_length\"]\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# # Setting random_state means the split will always be the same which sometimes is useful.\n",
    "# X_train, X_test, y_train, y_test =\\\n",
    "#     train_test_split(iris_df[X_FEATURES], iris_df[Y_TARGET], test_size=0.3, random_state=seed, stratify=iris_df[Y_TARGET])\n",
    "\n",
    "# # Output the dimensions of each of the sets\n",
    "# print(f\"X_train is {X_train.shape}\")\n",
    "# print(f\"X_test is {X_test.shape}\")\n",
    "# print(f\"y_train is {y_train.shape}\")\n",
    "# print(f\"y_test is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# lr_model = LogisticRegression(max_iter=1000)\n",
    "# lr_model.fit(X_train, y_train)\n",
    "# y_predict = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Report performance of classifier\n",
    "# # Note: This task achieves a perfect score\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"Other\", \"Setosa\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the decision boundary\n",
    "# # This assumes only TWO input features the X and Y in\n",
    "# #    y = mx + c\n",
    "\n",
    "# # The coefficients and intercepts applied to the X and Y\n",
    "# #   wY*y = wX*x + b\n",
    "# wX, wY = lr_model.coef_.T\n",
    "# b = lr_model.intercept_[0]\n",
    "# # Gradient and y-intercept for plotting (divide out wY)\n",
    "# #   y = mx + c\n",
    "# m = -wX/wY\n",
    "# c = -b/wY\n",
    "\n",
    "# # Find the minimum and maximum petal dimensions\n",
    "# # Make sure X was first feature, Y was second feature\n",
    "# xmin = iris_df[X_FEATURES[0]].min()\n",
    "# xmax = iris_df[X_FEATURES[0]].max()\n",
    "# ymin = iris_df[X_FEATURES[1]].min()\n",
    "# ymax = iris_df[X_FEATURES[1]].max()\n",
    "\n",
    "# # Calculate two points on the decision boundary\n",
    "# x_boundary = np.array([xmin, xmax])\n",
    "# y_boundary = m*x_boundary + c\n",
    "\n",
    "# # Plot the data and a line along the boundary\n",
    "# g = sns.scatterplot(data=iris_df, x=\"petal_width\", y=\"petal_length\", hue=Y_TARGET)\n",
    "# g = sns.lineplot(x=x_boundary, y=y_boundary, color='red', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Try using the exact same process to separate _versicolor_ and _virginica_ (after dropping _setosa_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a temporary copy of the data with setosa dropped\n",
    "# # Note: All iris_df have to be replaced with tmp_df in this block\n",
    "# tmp_df = iris_df[iris_df[\"setosa\"]==0].copy()\n",
    "# # Recode the flower types into the binary classes\n",
    "# Y_TARGET = \"versicolor\"\n",
    "# tmp_df[Y_TARGET] = tmp_df[\"flower_type\"].replace({\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 0})\n",
    "# print(\"== Distribution ==\")\n",
    "# print(tmp_df[Y_TARGET].value_counts())\n",
    "\n",
    "# ## Training and Test Data\n",
    "# X_FEATURES = [\"petal_width\", \"petal_length\"]\n",
    "# X_train, X_test, y_train, y_test =\\\n",
    "#     train_test_split(tmp_df[X_FEATURES], tmp_df[Y_TARGET], test_size=0.3, random_state=seed, stratify=tmp_df[Y_TARGET])\n",
    "\n",
    "# # Output the dimensions of each of the sets\n",
    "# print(\"\\n== Dimensions ==\")\n",
    "# print(f\"X_train is {X_train.shape}\")\n",
    "# print(f\"X_test is {X_test.shape}\")\n",
    "# print(f\"y_train is {y_train.shape}\")\n",
    "# print(f\"y_test is {y_test.shape}\")\n",
    "\n",
    "# # Logistic Regression\n",
    "# lr_model = LogisticRegression(max_iter=1000)\n",
    "# lr_model.fit(X_train, y_train)\n",
    "# y_predict = lr_model.predict(X_test)\n",
    "\n",
    "# # Report performance of classifier\n",
    "# print(\"\\n== Classification Report ==\")\n",
    "# print(classification_report(y_test, y_predict, target_names=[\"Virginica\", \"Versicolor\"]))\n",
    "\n",
    "# # Plot the decision boundary\n",
    "# wX, wY = lr_model.coef_.T\n",
    "# b = lr_model.intercept_[0]\n",
    "# m = -wX/wY\n",
    "# c = -b/wY\n",
    "# xmin = tmp_df[X_FEATURES[0]].min()\n",
    "# xmax = tmp_df[X_FEATURES[0]].max()\n",
    "# ymin = tmp_df[X_FEATURES[1]].min()\n",
    "# ymax = tmp_df[X_FEATURES[1]].max()\n",
    "# x_boundary = np.array([xmin, xmax])\n",
    "# y_boundary = m*x_boundary + c\n",
    "# g = sns.scatterplot(data=tmp_df, x=\"petal_width\", y=\"petal_length\", hue=Y_TARGET)\n",
    "# g = sns.lineplot(x=x_boundary, y=y_boundary, color='red', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "This has some errors so use a Receiver Operating Characteristic (ROC) to assess performance of _true-positive_ and _false-positive_ cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the ROC and area under the curve (AUC)\n",
    "# class_probs = lr_model.predict_proba(X_test)\n",
    "# prob_versicolor = class_probs[:, 1] # all rows, column 1 (2nd column)\n",
    "# fp_rate, tp_rate, _ = roc_curve(y_test, prob_versicolor)\n",
    "# roc_auc = auc(fp_rate, tp_rate)\n",
    "\n",
    "# # Plot the ROC\n",
    "# g = sns.lineplot(x=fp_rate, y=tp_rate)\\\n",
    "#        .set(title=\"ROC\", xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\")\n",
    "# g = sns.lineplot(x=[0, 1], y=[0, 1], color='r', linestyle='--')\n",
    "# _ = g.legend(labels=[f\"AUC = {roc_auc:0.4f}\"])\n",
    "# _ = sns.move_legend(g, \"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "The _versicolor_ and _virginica_ could not be linearly separated using only the petal dimensions.\n",
    "\n",
    "This example uses a Decision Tree across sepal and petal dimensions to try and classify all three types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an integer coding for all three of the target classes\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.factorize.html\n",
    "Y_TARGET = \"flower_target\"\n",
    "iris_df[Y_TARGET] = iris_df[\"flower_type\"].replace({\"Iris-setosa\": 1, \"Iris-versicolor\": 2, \"Iris-virginica\": 3})\n",
    "# Training and Test Data\n",
    "X_FEATURES = [\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\"]\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Setting random_state means the split will always be the same which sometimes is useful.\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(iris_df[X_FEATURES], iris_df[Y_TARGET], test_size=0.3, random_state=seed, stratify=iris_df[Y_TARGET])\n",
    "\n",
    "# Output the dimensions of each of the sets\n",
    "print(f\"X_train is {X_train.shape}\")\n",
    "print(f\"X_test is {X_test.shape}\")\n",
    "print(f\"y_train is {y_train.shape}\")\n",
    "print(f\"y_test is {y_test.shape}\")\n",
    "\n",
    "# Setup a Decision Tree \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "dt_model = DecisionTreeClassifier(criterion=\"gini\", random_state=seed)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_predict = dt_model.predict(X_test)\n",
    "\n",
    "# Report performance of classifier\n",
    "print(\"\\n== Classification Report ==\")\n",
    "print(classification_report(y_test, y_predict, target_names=[\"Setosa\", \"Versicolor\", \"Virginica\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Using all four of the features means accuracy and decision boundaries are more complex one alternative is to plot the decision tree itself. In this figure $X[0]$ means the first input feature $sepal\\_width$ and $X[3]$ means the fourth input feature $petal\\_length$. The $value$ line is the count of instances in each of the three classes. The tree immediately classifies all of the first class (_setosa_) on the basis of $X[3]<=2.6$ i.e. petal_length less than or equal to 2.6cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Tree using the lower-level plotting functions\n",
    "print(f\"X = {X_FEATURES}\")\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "\n",
    "_ = plot_tree(dt_model, filled=True, feature_names=X_FEATURES, class_names=[\"Setosa\", \"Versicolor\", \"Virginica\"])\n",
    "_ = plt.title(\"Decision Tree for Iris Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 4dp of each feature importance \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.feature_importances_\n",
    "# See the following for an explanation, but note this a regression example so uses MSE rather than GINI\n",
    "# https://towardsdatascience.com/feature-importance-in-decision-trees-e9450120b445\n",
    "for i, feature in enumerate(X_FEATURES):\n",
    "    print(f\"{feature}: {dt_model.feature_importances_[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9e7ae6ed9dc89a319e6ea230fd199155ded056bc8dab5f3cdbc9f526b4de7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
